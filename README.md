# Awesome-Token-Compress
A paper list of some recent  works about Token Compress for Vit and VLM
## VLM
### 2024
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2409.03420-red?logo=arxiv" height="14" />  [mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding](https://arxiv.org/abs/2409.03420) .    [mPLUG-DocOwl2;[Github](https://github.com/X-PLUG/mPLUG-DocOwl)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2409.01156-red?logo=arxiv" height="14" />  [TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval](https://arxiv.org/pdf/2409.01156) .    [TempMe;Video;[Github](https://github.com/X-PLUG/mPLUG-DocOwl)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2409.01179-red?logo=arxiv" height="14" />  [Recoverable Compression: A Multimodal Vision Token Recovery Mechanism Guided by Text Information](https://arxiv.org/pdf/2409.01179) . [Recoverable Compression]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2407.14439-red?logo=arxiv" height="14" />  [Token-level Correlation-guided Compression for Efficient Multimodal Document Understanding](https://arxiv.org/pdf/2407.14439) .    [Token-level;[Github](https://github.com/JiuTian-VL/TokenCorrCompressor)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2407.02392-red?logo=arxiv" height="14" />  [TokenPacker: Efficient Visual Projector for Multimodal LLM](https://arxiv.org/abs/2407.02392.pdf) .    [TokenPacker;[Github](https://github.com/CircleRadon/TokenPacker)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2404.16821-red?logo=arxiv" height="14" />  [How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites](https://arxiv.org/abs/2404.16821.pdf) .    [InternVL;Pixel-Shuffle;[Github](https://github.com/OpenGVLab/InternVL)]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2404.08567-red?logo=arxiv" height="14" />  [CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal Model Inference](https://arxiv.org/pdf/2404.08567) .    [CATP;]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2403.15388-red?logo=arxiv" height="14" />  [LLaVA-PruMerge:
Adaptive Token Reduction for Efficient Large Multimodal Models](https://arxiv.org/abs/2403.15388.pdf) .  [LLaVA-PruMerge;[Github](https://github.com/42Shawn/LLaVA-PruMerge)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2403.06764-red?logo=arxiv" height="14" />  [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-PLay Acceleration for VLLM Inference](https://arxiv.org/pdf/2403.06764) .  [FastV;ECCV 2024;[Github](https://github.com/pkunlp-icler/FastV)]

-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2402.03766-red?logo=arxiv" height="14" />  [MobileVLM V2: Faster and Stronger Baseline for Vision Language Model](https://arxiv.org/abs/2402.03766.pdf) .    [LDP-v2;[Github](https://github.com/Meituan-AutoML/MobileVLM)]

### 2023
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2312.06742-red?logo=arxiv" height="14" /> [Honeybee: Locality-enhanced Projector for Multimodal LLM](https://arxiv.org/abs/2312.06742) . [CVPR 2024;C-Abstractor;[Github](https://github.com/khanrc/honeybee?tab=readme-ov-file) ] 
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2308.12966-red?logo=arxiv" height="14" /> [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://arxiv.org/pdf/2308.12966v2) . [Resampler;[Github](https://github.com/QwenLM/Qwen-VL)]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2305.17455-red?logo=arxiv" height="14" /> [CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers](https://arxiv.org/pdf/2305.17455v4) . [CrossGET;	ICML 2024;[Github](https://github.com/sdc17/CrossGET)]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2301.125972-red?logo=arxiv" height="14" /> [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.125972) . [Q-former;[Github](https://github.com/salesforce/LAVIS/tree/main/projects/blip2)]
## Vit
### 2024
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2408.06798-red?logo=arxiv" height="14" />  [Token Compensator: Altering Inference Cost of Vision Transformer without Re-Tuning](https://arxiv.org/pdf/2408.06798) . [Token Compensator;ToCom;[Github](https://github.com/JieShibo/ToCom)]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2408.06840-red?logo=arxiv" height="14" />  [Dynamic and Compressive Adaptation of Transformers From Images to Videos](https://arxiv.org/pdf/2408.06840) . [InTI;] 
### 2023
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2305.17997-red?logo=arxiv" height="14" />  [PPT: Token Pruning and Pooling for Efficient Vision Transformers](https://arxiv.org/pdf/2310.01812) . [PPT;[Github](https://github.com/xjwu1024/PPT)] 
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2305.17997-red?logo=arxiv" height="14" />  [DiffRate : Differentiable Compression Rate for Efficient Vision Transformers](https://arxiv.org/abs/2305.17997) . [DiffRate;ICCV 2023;[Github](https://github.com/OpenGVLab/DiffRate)] 
### 2022
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2210.09461-red?logo=arxiv" height="14" /> [TOKEN MERGING: YOUR VIT BUT FASTER](https://arxiv.org/pdf/2210.09461) . [ToMe;Token Merging; ICLR 2023]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2209.13802-red?logo=arxiv" height="14" /> [Adaptive Sparse ViT: Towards Learnable Adaptive Token Pruning by Fully Exploiting Self-Attention](https://arxiv.org/pdf/2209.13802) . [Adaptive Sparse ViT]
-  <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2202.07800-red?logo=arxiv" height="14" /> [EViT: Expediting Vision Transformers via Token Reorganizations](https://arxiv.org/pdf/2202.07800) . [EViT;ICLR 2022;[Github](https://github.com/youweiliang/evit?tab=readme-ov-file)]
### 2021
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2112.07658-red?logo=arxiv" height="14" /> [A-ViT: Adaptive Tokens for Efficient Vision Transformer](https://arxiv.org/pdf/2112.07658) . [A-Vit;]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2111.15667-red?logo=arxiv" height="14" /> [ATS: Adaptive Token Sampling For Efficient Vision Transformers](https://arxiv.org/abs/2111.15667) . [ATS;ECCV 2022;[Github](https://github.com/adaptivetokensampling/ATS)]
- <img alt="arXiv" src="https://img.shields.io/badge/arXiv-2106.02034-red?logo=arxiv" height="14" /> [DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsificationr](https://arxiv.org/abs/2106.02034) . [DynamicViT;NeurIPS 2021;[Github](https://github.com/raoyongming/DynamicViT)]
  




